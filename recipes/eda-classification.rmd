---
title: 'EDA for Binary Classification'
author: 'Mark Newman'
date: '2021-04-12'
editor_options: 
  chunk_output_type: console
---

This recipe explores one of the various ways to visually explore data before using a binary classifier.
The aim here is to provide an automatic process that is close to a drag-and-drop method.

# Why?

> A picture is worth a thousand words

Having a copy-paste process for EDA is useful in getting any research off the ground.

# What?

```{r child = '../datasets/heartattack.rmd'}
```

Separate out the categorical and continuous predictors.

```{r label = 'separate'}
cn <- colnames(data)
cn <- cn[!(cn %in% class)]
indx <- sapply(cn, function(x){is.factor(data[,x])})
colnames_cat <- cn[indx]
colnames_cont <- cn[!indx]
rm(cn, indx)
```

Re-`level()` all the factors based on frequency to allow the figures to show up cleaner.
We may consider skipping this step if there is a compelling reason I.E. the data is not nominal, but ordinal (`ordered()`).

```{r label = 'relevel'}
for(cn in colnames_cat) {
  t1 <- data[,cn]
  if(!is.ordered(t1)) {
    t1 <- table(data[,cn])
    t1 <- sort(t1, decreasing = T)
    t1 <- names(t1)
    data[,cn] <- factor(data[,cn], levels = t1)
  }
  rm(t1)
}
rm(cn)
```

# Results

When we display the visuals for the EDA, we want them to be in an order that makes sense.
The default should be in an order that makes sense for the dataset.
This allows for the best story to be presented.

Baring that, a _reasonable_ alternative is largest absolute test statistic
In this case the ordering can be seen below.

```{r label = 'helper functions test'}
library(knitr)
library(kableExtra)

test_cont <- function(data, class, predictor) {
  t1 <- data[,c(class, predictor)]
  colnames(t1) <- c('Class', 'Value')
  t.test(Value ~ Class, data = t1)
}
test_cat <- function(data, class, predictor) {
  t1 <- table(data[,class], data[,predictor])
  chisq.test(t1)
}
format_pvalue <- function(pv) {
  if(pv > 0.05) {
    '> 0.05'
  } else if(pv < 0.001) {
    '< 0.001'
  } else {
    paste0('= ', round(pv, 3))
  }
}
univariate_test_all <- function(data, test, class, predictors) {
  df1 <- data.frame(pre = predictors, stat = as.numeric(NA), df = NA, pv = NA)
  rownames(df1) <- predictors
  for(predictor in predictors) {
    t1 <- test(data, class, predictor)
    df1[predictor, 'stat'] <- t1$statistic
    df1[predictor, 'df'] <- t1$parameter
    df1[predictor, 'pv'] <- format_pvalue(t1$p.value)
    rm(t1)
  }
  rm(predictor)
  df1 <- df1[order(abs(df1$stat), decreasing  = T),]
  rownames(df1) <- NULL
  df1
}
render_test_all <- function(table, test_stat) {
  t1 <-
    kable(
      table,
      caption = 'Univariate Results',
      col.names = c('Predictor', test_stat, 'DF', 'P Value'),
      digits = c(0, 2, 2, 0))
  kable_styling(t1)
}
```

Using the univariate tests of `t.test()` and `chisq.test()` we can see the relationship between the individual `predictor`s and the class ``r class``.
**NOTE**: When combining this work with other work, remember to adjust the p-values to prevent an inflated alpha error.

```{r label = 'results test', echo = F, message = F, warning = F}
t1 <- univariate_test_all(data, test_cont, class, colnames_cont)
t2 <- univariate_test_all(data, test_cat, class, colnames_cat)
render_test_all(t1, '$t$')
render_test_all(t2, '$\\chi^2$')
rm(test_cont, test_cat, format_pvalue, univariate_test_all, render_test_all)
rm(colnames_cont, colnames_cat)
```

```{r label = 'helper functions figure', message = F, warning = F}
library(vcd)
library(ggplot2)

univariate_figure_cont <- function(data, class, predictors) {
  for(predictor in predictors) {
    t1 <- data[,c(class, predictor)]
    colnames(t1) <- c('Class', 'Value')
    p1 <-
      ggplot(t1, aes(x = Value, color = Class)) + 
      scale_color_brewer(palette = 'Dark2') + 
      geom_line(stat = 'ecdf') + 
      theme_bw() +
      labs(
        x = predictor,
        y = 'Cumulative Density',
        color = class)
    plot(p1)
  }
}
univariate_figure_cat <- function(data, class, predictors) {
  for(predictor in predictors) {
    t1 <- data[,c(class, predictor)]
    colnames(t1) <- c('Class', 'Value')
    t1 <- xtabs(~ Class + Value, data = t1)
    t2 <- dimnames(t1)
    names(t2) <- c(class, predictor)
    dimnames(t1) <- t2
    mosaic(
      t1,
      labeling = labeling_values(rot_labels = c(45, 90, 0, 90)),
      shade = T)
  }
}
```

Visualizations of the above tests can be seen below.

```{r label = 'results figure', echo = F}
univariate_figure_cont(data, class, t1$pre)
univariate_figure_cat(data, class, t2$pre)
rm(univariate_figure_cont, univariate_figure_cat)
```

```{r label = 'final cleanup', echo = F}
rm(data, t1, t2, class, formula)
```



